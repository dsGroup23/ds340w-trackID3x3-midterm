# TrackID3x3 â€“ Final Project (DS 340W)

This repository contains my final project for **DS 340W**.  
Starting from the public **TrackID3x3 / CAMELTrack** 3Ã—3 basketball tracking code, I built an end-to-end, light-weight pipeline that:

1. **Uses pre-computed tracker outputs** (MOT format) for 3Ã—3 basketball games.  
2. **Applies a new post-processing step** (trajectory smoothing + short-track filtering) to clean the player and ball tracks.  
3. **Evaluates tracking quality** with **TI-HOTA** metrics on an indoor 3Ã—3 dataset, and  
4. **Compares â€œBaseline vs. OURSâ€** with summary statistics and a scatter plot.

The goal is that anyone (instructor / TA) can reproduce the results on a laptop **without running any heavy detection / tracking models**.

---

## 1. Repository structure

At the top level you will see:

```text
TrackID3x3/
â”œâ”€â”€ BoT-SORT/                 # Third-party multi-object tracker (not re-run in this project)
â”œâ”€â”€ CAMELTrack/               # Upstream CAMELTrack detection + tracking code (not re-run)
â”œâ”€â”€ CAMELTrack_outputs/       # Pre-computed baseline tracker outputs (MOT text files)
â”œâ”€â”€ anaconda_projects/        # Conda / Anaconda environment helper (optional)
â”‚   â””â”€â”€ db/                   # Environment metadata from my local setup
â”œâ”€â”€ court_images/             # Court images for homography / visualization (from parent repo)
â”œâ”€â”€ ground_truth/             # 3Ã—3 tracking ground truth in MOT format
â”‚   â””â”€â”€ Indoor/
â”‚       â””â”€â”€ transformed_MOT_with_attributes/
â”œâ”€â”€ jersey-number-pipeline/   # Jersey number recognition code (not used in final evaluation)
â”œâ”€â”€ output/                   # Outputs produced in this project (OURS)
â”‚   â””â”€â”€ CAMELTrack_outputs/
â”‚       â””â”€â”€ Indoor/
â”‚           â”œâ”€â”€ filtered_MOT/         # Copy of baseline filtered tracks (for safety)
â”‚           â””â”€â”€ filtered_MOT_smooth/  # ***Our smoothed & cleaned tracks***
â”œâ”€â”€ script/                   # Helper scripts / notebooks for analysis
â”œâ”€â”€ videos/                   # Small demo clips / GIFs only (no large .mp4 in Git)
â”‚   â””â”€â”€ gif/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitmodules               # For BoT-SORT and CAMELTrack submodules
â”œâ”€â”€ LICENSE.md
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ Untitled.ipynb            # Smoothing & saving OURS tracks (see Section 4.2)
â”œâ”€â”€ Untitled1.ipynb           # TI-HOTA evaluation (Baseline vs. OURS)
â””â”€â”€ Untitled2.ipynb           # Extra analysis / plots (optional)


## 2. Dataset

This project is built on top of the **TrackID3x3** 3x3 basketball tracking dataset.

### 2.1 Data used in _this_ repository

For grading and reproduction, **you do NOT need to download any external data**.  
All the files required to re-run our pipeline are already included in this repo:

- `ground_truth/Indoor/transformed_MOT_with_attributes/`  
  - Cleaned ground-truth MOT files for the Indoor subset  
  - Each `.txt` file contains: `frame_id, id, x, y, w, h, conf, cls, vis, empty`

- `output/CAMELTrack_outputs/Indoor/filtered_MOT/`  
  - Baseline tracker outputs (CAMELTrack) in MOT text format  
  - Used as **Baseline** prediction in our evaluation

- `output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth/`  
  - Our **smoothed & cleaned** tracking results  
  - Generated by `notebooks/Untitled.ipynb` (smoothing) and used as **OURS** prediction

- `court_images/`  
  - Court reference images used when computing court coordinates / TI-HOTA metrics

> ðŸš« Raw video files and very large zip files are **not** stored in this repo because of GitHubâ€™s 100 MB per-file limit.  
> They are **not required** to re-run our experiments or reproduce our tables/figures.

### 2.2 Original TrackID3x3 dataset (reference)

The processed MOT files above were derived from the **TrackID3x3** dataset:

> Kazuhiro Yamada et al.,  
> *â€œTrackID3x3: A Dataset and Algorithm for Multi-Player Tracking with Identification and Pose Estimation in 3x3 Basketball Full-court Videos.â€*   

According to the paper, the official dataset and code will be hosted at:

- GitHub: `https://github.com/open-starlab/TrackID3x3`   

If someone wants to work with the **original full-court videos** (Indoor / Outdoor / Drone),  
they should request or download the data from the official TrackID3x3 project and then follow
our preprocessing steps to obtain the MOT text files used here. https://drive.google.com/drive/folders/1aWqMwQKr5xKMjqms7-raYluSlxPsGvwX
and you can download the original datasets here.

2. Conda environment & dependencies

The project was developed in Python 3.10 on macOS with a standard data-science stack.
The minimal dependencies needed to run the notebooks are:

numpy

pandas

matplotlib

opencv-python (imported as cv2)

jupyter

You can create a clean Conda environment like this:

# From anywhere
conda create -n trackid3x3 python=3.10 -y
conda activate trackid3x3

# Basic packages
pip install numpy pandas matplotlib opencv-python jupyter


If you prefer, you can also use the environment metadata in anaconda_projects/db as a reference, but it is not required.

3. Data overview
3.1 Ground truth (Indoor 3Ã—3)

Location: ground_truth/Indoor/transformed_MOT_with_attributes/

Format: MOT text files, one file per video.

Columns (no header):

frame_id, id, x, y, w, h, conf, cls, vis, empty


frame_id: frame index

id: object ID

x, y, w, h: bounding box (top-left + width/height) in image coordinates

conf: detection confidence

cls: class label

vis: visibility flag

empty: reserved / unused column

These files are used as ground truth for TI-HOTA evaluation.

3.2 Baseline tracker outputs

Location: CAMELTrack_outputs/Indoor/filtered_MOT/

Content: MOT-style tracker outputs produced by the upstream CAMELTrack pipeline.

Same column format as above.

These files represent the baseline tracking results (without my post-processing).

3.3 Our smoothed & cleaned outputs (OURS)

Location: output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth/

These are created from the baseline outputs by running my smoothing notebook (Section 4.2).

Changes compared to baseline:

Temporal smoothing of the (x, y) coordinates using a centered rolling mean (window=5).

Short-track filtering: tracks shorter than 10 frames are removed.

Outputs are written back to MOT text files with the same structure and file names as the baseline.

These files are used as the OURS predictions in the TI-HOTA evaluation.


4. How to reproduce my results

All steps below assume you are in the repo root, e.g.

cd path/to/TrackID3x3
conda activate trackid3x3

4.1 Check data paths in the notebooks

For portability, the notebooks use relative paths from the repo root.
In each notebook, the main directories should look like:

# Example used in my notebooks

GT_FOLDER  = "./ground_truth/Indoor/transformed_MOT_with_attributes"
BASE_PRED_FOLDER = "./CAMELTrack_outputs/Indoor/filtered_MOT"
OURS_PRED_FOLDER = "./output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth"


If you ever move the project, please just make sure these paths are still correct.

4.2 Step 1 â€“ Generate smoothed tracks (OURS)

Notebook: Untitled.ipynb
(You can rename it to 01_smooth_tracks.ipynb if you like; the logic is described here.)

Launch Jupyter from the repo root:

jupyter notebook


Open Untitled.ipynb.

Run all cells from top to bottom. The key parts of the notebook are:

import os
import glob
import pandas as pd

IN_DIR  = "./CAMELTrack_outputs/Indoor/filtered_MOT"
OUT_DIR = "./output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth"

os.makedirs(OUT_DIR, exist_ok=True)

mot_files = glob.glob(os.path.join(IN_DIR, "*.txt"))
print(f"Found {len(mot_files)} MOT files.")


For each MOT file, the notebook:

Reads it into a pandas.DataFrame.

Sorts rows by ("id", "frame_id").

Applies a rolling mean with window=5 on the x and y columns (per track ID).

Drops tracks shorter than 10 frames.

Writes the result to OUT_DIR with the same file name.

At the end you should see a log similar to:

Found 40 MOT files.
Processed basket_S3T6_pre.txt -> ./output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth/basket_S3T6_pre.txt
...
All files processed. Smoothed results saved to ./output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth


After this step, output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth/ will contain our cleaned/smoothed MOT files.

4.3 Step 2 â€“ Compute TI-HOTA metrics (Baseline & OURS)

Notebook: Untitled1.ipynb
(You can rename it to 02_compute_ti_hota.ipynb.)

This notebook evaluates both the baseline and our smoothed tracks against the same ground truth using TI-HOTA.

Core logic (simplified):

import os
import glob
import numpy as np

from ti_hota_utils import load_video, compute_ti_hota  # provided by parent repo

GT_FOLDER      = "./ground_truth/Indoor/transformed_MOT_with_attributes"
BASE_PRED_DIR  = "./CAMELTrack_outputs/Indoor/filtered_MOT"
OURS_PRED_DIR  = "./output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth"
tau = 100

gt_files = glob.glob(os.path.join(GT_FOLDER, "*.txt"))

baseline_results = []   # list of metric dicts, one per video
ours_results      = []  # list of metric dicts, one per video
frame_counts      = []  # number of frames per video


For each gt_file:

It finds the corresponding prediction file in the baseline folder and in the OURS folder.

Uses load_video(gt_file, pred_file) to build per-frame structures.

Calls compute_ti_hota(frames, tau) to get a metric dictionary with keys:

TI-HOTA

TI-DetA

TI-AssA

TI-TP, TI-FP, TI-FN

Prints per-video results and appends the metrics to baseline_results / ours_results.

At the bottom, the notebook aggregates mean Â± standard deviation across all videos.
You will see text similar to:

===== Indoor Videos (Baseline, Ï„=100) : Mean Â± SD =====
Frame Count: 179.38 (std: 64.77)
TI-HOTA: 0.0XXX (std: 0.0XXX)
TI-DetA: 0.0XXX (std: 0.0XXX)
TI-AssA: 0.0XXX (std: 0.0XXX)
TI-TP:   XXXX.XX (std: XXX.XX)
TI-FP:   XXXX.XX (std: XXX.XX)
TI-FN:   XXXX.XX (std: XXX.XX)

===== Indoor Videos (OURS, Ï„=100) : Mean Â± SD =====
Frame Count: 179.38 (std: 64.77)
TI-HOTA: 0.0226 (std: 0.0173)   # example numbers
...


These tables are what I use in the report to summarize the effect of my smoothing/cleaning step.

4.4 Step 3 â€“ Scatter plot: Per-video TI-HOTA (Baseline vs OURS)

Notebook: Untitled2.ipynb
(You can rename it to 03_plot_baseline_vs_ours.ipynb.)

This notebook assumes that baseline_results and ours_results have already been computed (e.g., by re-running the relevant code or by re-importing the utility functions). It then builds a scatter plot comparing per-video TI-HOTA:

import numpy as np
import matplotlib.pyplot as plt

baseline_dict = {name: m for name, m in baseline_results}
ours_dict     = {name: m for name, m in ours_results}

common_names = sorted(set(baseline_dict.keys()) & set(ours_dict.keys()))

base_hota = [baseline_dict[n]["TI-HOTA"] for n in common_names]
ours_hota = [ours_dict[n]["TI-HOTA"]     for n in common_names]

fig, ax = plt.subplots(figsize=(5, 5))
ax.scatter(base_hota, ours_hota)

min_val = min(base_hota + ours_hota)
max_val = max(base_hota + ours_hota)
ax.plot([min_val, max_val], [min_val, max_val], linestyle="--")  # y = x line

ax.set_xlabel("Baseline TI-HOTA")
ax.set_ylabel("OURS TI-HOTA")
ax.set_title("Per-video TI-HOTA: Baseline vs OURS")

plt.tight_layout()
plt.show()


If our smoothing step is helpful, points that lie above the diagonal line correspond to videos where OURS has higher TI-HOTA than the baseline.


5. What is new in this project (relative to the parent GitHub)

The original TrackID3x3 / CAMELTrack repository focused on:

Building a full pipeline from detection â†’ tracking â†’ court homography â†’ downstream analytics.

Providing pre-trained models and baseline tracking outputs.

Our contributions in this final project are:

A post-processing module for tracker outputs

Implemented in Untitled.ipynb (smoothing + short-track filtering).

Designed to be lightweight and easy to run on any laptop.

A TI-HOTA evaluation pipeline

Reads both baseline and OURS MOT files.

Outputs per-video and dataset-level metrics (TI-HOTA, TI-DetA, TI-AssA, TI-TP, TI-FP, TI-FN).

Implemented entirely in Python using NumPy/Pandas, leveraging helper functions from the parent repo.

Baseline vs OURS analysis & visualization

Aggregated mean Â± std statistics for the indoor 3Ã—3 dataset.

A per-video scatter plot (Baseline TI-HOTA vs OURS TI-HOTA) for visual inspection of improvements / regressions.

All of these additions are contained in this repository and can be reproduced by following Sections 4.2â€“4.4.

6. How to quickly verify that everything works

For grading convenience, here is the shortest path to check that the code runs:

# 1. Clone and enter the repo
git clone https://github.com/dsGroup23/TrackID3x3.git
cd TrackID3x3

# 2. Create / activate environment
conda create -n trackid3x3 python=3.10 -y
conda activate trackid3x3
pip install numpy pandas matplotlib opencv-python jupyter

# 3. Run Jupyter
jupyter notebook


Then:

Open Untitled.ipynb, run all cells â€“ this will create smoothed MOT files in
output/CAMELTrack_outputs/Indoor/filtered_MOT_smooth/.

Open Untitled1.ipynb, run all cells â€“ this will print TI-HOTA metrics for both
Baseline and OURS.

(Optional) Open Untitled2.ipynb to generate the Baseline vs. OURS scatter plot.

If these three steps run without error and produce the printed tables & plot, the project has been successfully reproduced.

7. Acknowledgements

Original tracking & dataset code from the public TrackID3x3 / CAMELTrack and BoT-SORT repositories.

TI-HOTA metric implementation based on the official HOTA / TI-HOTA code provided by the authors.

DS 340W course staff for guidance on structuring reproducible data-science projects.


